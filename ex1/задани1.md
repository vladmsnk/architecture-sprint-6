## Проектирование технологической архитектуры

#### Нефункциональные требования 
- RTO — 45 мин
- RPO — 15 мин
- стабильное latency для функционала загрузки страниц для пользователей из разных регионов

#### Анализ текущих проблем
- Сайт медленно загружает страницы: запрос на загрузку страницы приходит в монолитный бэкенд core-app. 
Операции чтения могут конкурировать с операциями записи в моменты, когда производятся запросы на создание/покупки страховок.
- Оформление новых страховок происходит так, что происходит синхронное обращение c помощью REST к стороннему сервисам взаимодействия со страховыми компаниями.
То есть долгий ответ со стороны сервисов-поставщиков страховок сторонних компаний может негативно сказываться на работу всего
сервиса core-app
- В случае если монолит core-api statefull, значительно усложняется горизонтальное масштабирование.
В этом случае потребуется дополнительная декомпозиция монолита на микросервисы. 
- Уязвимость одно экземпляра PostgreSQL, развернутого в VM. Отсутствие failover стратегии для БД. 
В случае отказа узла, недостаток реплик влияет на Repair Time
- Проблема с перегрузкой со API для B2B 
- Отсутствие мониторинга, что влияет на метрику MTTR
- Не предусмотрен autoscalling на уровне инфраструктуры

#### Стратегия масштабирования

Судя по описанию сервиса core-api, он является stateless, тк он не хранит промежуточного состояния системы.
Поэтому, ничего не препятсвует в использовании горизонтального масштабирования системы.
Будем считать, что каждый сервис в k8s кластере будет развернут в отдельном поде.

**Этапы масштабирования**

1) На первом этапе улучшения инфраструктуры достаточно будет настроить горизонтальное масштабирование подов сервиса core-api. А 
все остальные сервисы оставить в единственном экземпляре. Все это выполняется в рамках одной зоны.
- создаем deployment для сервиса core-app и настраиваем начальное количество реплик данного сервиса
- добавляем новые ноды в кластер для того, чтобы поды core-app были разбросаны на нескольких нодах в рамках одной зоны

2) На втором этапе настроить кластер на масштабирование отдельных подов с использованием HorizontalPodAutoscaler.
- устанавливаем metrics server в кластер
- для начала можно создать объект HPA, ориентированный на целевые метрики загруженности CPU
- в дальнейшем можно указать конкретную метрику, например, RPS, по которой будет происходить автоскейлинг. Для
этого необходимо будет поднять Prometheus Operator 

3) Далее, для лучше доступности сервиса в разных регионах, подключаем две дополнительные зоны доступности, 
регистрируем новые ноды в k8s кластер и настраиваем необходимое распределение подов по остальным нодам.
Примерное решение:
- Добавляем новые ноды в кластер из новых зон
- каждой новой ноде добавляем метки (zone_2, zone_3)
- старым нодам из первой зоны проставляем метку zone_1
- обновляем Deployment core-app с использованием nodeAffinity и podAntiAffinity, чтобы гарантировать равномерное распределение реплик по зонам
- настраиваем GSLB, который будет направлять клиентский трафик на внешний IP-адрес, ассоциированный с ближайшей зоной 

**Анализ**
1) Используем растянутый кластер k8s для простоты настройки. В последующем, если обнаружится, что единственный растянутый
кластер вносит существенные задержки, а также для лучшей безопасности кластера, стоит перейти на использование нескольких
кластеров 
2) Для балансировки нагрузки будут использоваться:
- локальные балансировщики нагрузки в каждой зоне
- глобальный балансировщик GSLB для геораспределения трафика

GSLB будет располагаться перед локальными балансировщиками. Далее будет принимать DNS-запросы от клиентов
и, основываясь на географическом положении клиентов и текущем состоянии сервисов в каждой зоне, будет возвращать
ip адрес наиболее подходящего сервиса

3) Используем Active-Active failover-стратегию с использованием балансировщика на основе GSLB.
GSLB при определении запроса будет основываться на информации о текущей доступности, полученной с помощью
health-check.

**Шардирование**
На текущем этапе шардирование не принесет никакой пользы, а только внесет дополнительные сложности в архитектуру. 
Сейчас по условию сказано, что в базе хранится около 50GB клиентских данных. При небольших объемах данных интеграция шардирования
является избыточным. Затраты на интеграцию шардирования могут не перевесить выгоду от улучшения производительности, так как
ее может и не быть.
Более того, PostgreSQL не позволяет настроить шардирование из коробки, поэтому для того, чтобы исопльзовать
шардирование, нужны дополонительные инструменты (например, Citus)
